{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Week 2.6: Leakage-Controlled Evaluation\n",
                "\n",
                "**Purpose**: Run inference on original vs sanitized text to measure actual F1 delta.\n",
                "\n",
                "**Requires**: GPU runtime (T4 recommended)\n",
                "\n",
                "**Note**: This notebook uses your existing Week 2 checkpoint (upload required)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Clone Repository\n",
                "!git clone https://github.com/AngadSingh22/Text2Diag.git\n",
                "%cd Text2Diag"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install Dependencies\n",
                "!pip install -q torch transformers accelerate scikit-learn datasets pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Download Raw Dataset\n",
                "!python scripts/inspect_raw_datasets.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Build Canonical Dataset\n",
                "!python scripts/02_build_reddit_canonical.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. UPLOAD YOUR CHECKPOINT\n",
                "# \n",
                "# Instructions:\n",
                "# 1. On your local machine, ZIP the checkpoint folder:\n",
                "#    - Go to: f:\\Text2Diag\\results_week2\\results\\week2\\checkpoints\\\n",
                "#    - ZIP the 'checkpoint-4332' folder -> checkpoint-4332.zip\n",
                "#\n",
                "# 2. Run this cell - it will prompt you to upload the zip file\n",
                "#\n",
                "from google.colab import files\n",
                "import zipfile\n",
                "import os\n",
                "\n",
                "print(\"Please upload checkpoint-4332.zip from your local machine...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Extract the checkpoint\n",
                "os.makedirs(\"results/week2/checkpoints\", exist_ok=True)\n",
                "for filename in uploaded.keys():\n",
                "    print(f\"Extracting {filename}...\")\n",
                "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "        zip_ref.extractall(\"results/week2/checkpoints/\")\n",
                "    \n",
                "# Verify\n",
                "!ls -la results/week2/checkpoints/\n",
                "checkpoint_path = \"results/week2/checkpoints/checkpoint-4332\"\n",
                "print(f\"\\nCheckpoint ready: {checkpoint_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Run Leakage-Controlled Evaluation\n",
                "checkpoint_path = \"results/week2/checkpoints/checkpoint-4332\"\n",
                "\n",
                "!python scripts/09_eval_sanitized.py \\\n",
                "    --checkpoint {checkpoint_path} \\\n",
                "    --data_dir data/processed/reddit_mh_windows \\\n",
                "    --out_dir results/week2/remediation \\\n",
                "    --sanitize_config configs/sanitize.yaml \\\n",
                "    --batch_size 32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Check Results\n",
                "!cat results/week2/remediation/leakage_eval_metrics.md"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. View JSON Metrics\n",
                "import json\n",
                "with open('results/week2/remediation/leakage_eval_metrics.json', 'r') as f:\n",
                "    metrics = json.load(f)\n",
                "print(json.dumps(metrics, indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Zip and Download Results\n",
                "!zip -r w26_results.zip results/week2/remediation\n",
                "from google.colab import files\n",
                "files.download('w26_results.zip')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}